<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloud Provider Azure â€“ Known Issues</title><link>https://kubernetes-sigs.github.io/cloud-provider-azure/faq/known-issues/</link><description>Recent content in Known Issues on Cloud Provider Azure</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://kubernetes-sigs.github.io/cloud-provider-azure/faq/known-issues/index.xml" rel="self" type="application/rss+xml"/><item><title>FAQ: AzureDisk CSI Driver Known Issues</title><link>https://kubernetes-sigs.github.io/cloud-provider-azure/faq/known-issues/azuredisk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://kubernetes-sigs.github.io/cloud-provider-azure/faq/known-issues/azuredisk/</guid><description>
&lt;ul>
&lt;li>&lt;a href="#azure-disk-plugin-known-issues">azure disk plugin known issues&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#recommended-stable-version-for-azure-disk">Recommended stable version for azure disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="#1-disk-attach-error">1. disk attach error&lt;/a>&lt;/li>
&lt;li>&lt;a href="#2-disk-unavailable-after-attachdetach-a-data-disk-on-a-node">2. disk unavailable after attach/detach a data disk on a node&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-azure-disk-support-on-sovereign-cloud">3. Azure disk support on Sovereign Cloud&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-time-cost-for-azure-disk-pvc-mount">4. Time cost for Azure Disk PVC mount&lt;/a>&lt;/li>
&lt;li>&lt;a href="#5-azure-disk-pvc-multi-attach-error-makes-disk-mount-very-slow-or-mount-failure-forever">5. Azure disk PVC &lt;code>Multi-Attach error&lt;/code>, makes disk mount very slow or mount failure forever&lt;/a>&lt;/li>
&lt;li>&lt;a href="#6-waitforattach-failed-for-azure-disk-parsing-devdiskazurescsi1lun1-invalid-syntax">6. WaitForAttach failed for azure disk: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun1&amp;rdquo;: invalid syntax&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-uid-and-gid-setting-in-azure-disk">7. &lt;code>uid&lt;/code> and &lt;code>gid&lt;/code> setting in azure disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="#8-addition-of-a-blob-based-disk-to-vm-with-managed-disks-is-not-supported">8. &lt;code>Addition of a blob based disk to VM with managed disks is not supported&lt;/code>&lt;/a>&lt;/li>
&lt;li>&lt;a href="#9-dynamic-azure-disk-pvc-try-to-access-wrong-storage-account-of-other-resource-group">9. dynamic azure disk PVC try to access wrong storage account (of other resource group)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#10-data-loss-if-using-existing-azure-disk-with-partitions-in-disk-mount">10. data loss if using existing azure disk with partitions in disk mount&lt;/a>&lt;/li>
&lt;li>&lt;a href="#11-delete-azure-disk-pvc-which-is-already-in-use-by-a-pod">11. Delete azure disk PVC which is already in use by a pod&lt;/a>&lt;/li>
&lt;li>&lt;a href="#12-create-azure-disk-pvc-failed-due-to-account-creation-failure">12. create azure disk PVC failed due to account creation failure&lt;/a>&lt;/li>
&lt;li>&lt;a href="#13-cannot-find-Lun-for-disk">13. cannot find Lun for disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="#14-azure-disk-attachdetach-failure-mount-issue-io-error">14. azure disk attach/detach failure, mount issue, i/o error&lt;/a>&lt;/li>
&lt;li>&lt;a href="#15-azure-disk-could-be-not-detached-forever">15. azure disk could be not detached forever&lt;/a>&lt;/li>
&lt;li>&lt;a href="#16-potential-race-condition-issue-due-to-detach-disk-failure-retry">16. potential race condition issue due to detach disk failure retry&lt;/a>&lt;/li>
&lt;li>&lt;a href="#17-very-slow-disk-attachdetach-issue-when-disk-num-is-large">17. very slow disk attach/detach issue when disk num is large&lt;/a>&lt;/li>
&lt;li>&lt;a href="#18-detach-azure-disk-make-vm-run-into-a-limbo-state">18. detach azure disk make VM run into a limbo state&lt;/a>&lt;/li>
&lt;li>&lt;a href="#19-disk-attachdetach-self-healing-on-vmas">19. disk attach/detach self-healing on VMAS&lt;/a>&lt;/li>
&lt;li>&lt;a href="#20-azure-disk-detach-failure-if-node-not-exists">20. azure disk detach failure if node not exists&lt;/a>&lt;/li>
&lt;li>&lt;a href="#21-invalid-disk-URI-error">21. invalid disk URI error&lt;/a>&lt;/li>
&lt;li>&lt;a href="#22-vmss-dirty-cache-issue">22. vmss dirty cache issue&lt;/a>&lt;/li>
&lt;li>&lt;a href="#23-race-condition-when-delete-disk-right-after-attach-disk">23. race condition when delete disk right after attach disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="#24-attach-disk-costs-10min">24. attach disk costs 10min&lt;/a>&lt;/li>
&lt;li>&lt;a href="#25-multi-attach-error">25. Multi-Attach error&lt;/a>&lt;/li>
&lt;li>&lt;a href="#26-attached-non-existing-disk-volume-on-agent-node">26. attached non-existing disk volume on agent node&lt;/a>&lt;/li>
&lt;li>&lt;a href="#27-failed-to-get-azure-instance-id-for-node-not-a-vmss-instance">27. failed to get azure instance id for node (not a vmss instance)&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="recommended-stable-version-for-azure-disk">Recommended stable version for azure disk&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>stable version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.11+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.10+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.6+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.18&lt;/td>
&lt;td>1.18.3+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.19&lt;/td>
&lt;td>1.19.0+&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="1-disk-attach-error">1. disk attach error&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>In some corner case(detaching multiple disks on a node simultaneously), when scheduling a pod with azure disk mount from one node to another, there could be lots of disk attach error(no recovery) due to the disk not being released in time from the previous node. This issue is due to lack of lock before DetachDisk operation, actually there should be a central lock for both AttachDisk and DetachDisk operations, only one AttachDisk or DetachDisk operation is allowed at one time.&lt;/p>
&lt;p>The disk attach error could be like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Cannot attach data disk &lt;span style="color:#4e9a06">&amp;#39;cdb-dynamic-pvc-92972088-11b9-11e8-888f-000d3a018174&amp;#39;&lt;/span> to VM &lt;span style="color:#4e9a06">&amp;#39;kn-edge-0&amp;#39;&lt;/span> because the disk is currently being detached or the last detach operation failed. Please &lt;span style="color:#204a87">wait&lt;/span> &lt;span style="color:#204a87;font-weight:bold">until&lt;/span> the disk is completely detached and &lt;span style="color:#204a87;font-weight:bold">then&lt;/span> try again or delete/detach the disk explicitly again.
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/60101">Azure Disk Detach are not working with multiple disk detach on the same Node&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/46421">Azure disk fails to attach and mount, causing rescheduled pod to stall following node disruption&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2002">Since Intel CPU Azure update, new Azure Disks are not mounting, very critical&amp;hellip; &lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/ACS/issues/12">Busy azure-disk regularly fail to mount causing K8S Pod deployments to halt&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Mitigation&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>option#1: Update every agent node that has attached or detached the disk in problem&lt;/li>
&lt;/ul>
&lt;p>In Azure cloud shell, run&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#000">$vm&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> Get-AzureRMVM -ResourceGroupName &lt;span style="color:#000">$rg&lt;/span> -Name &lt;span style="color:#000">$vmname&lt;/span>
Update-AzureRmVM -ResourceGroupName &lt;span style="color:#000">$rg&lt;/span> -VM &lt;span style="color:#000">$vm&lt;/span> -verbose -debug
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In Azure cli, run&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">az vm update -g &amp;lt;group&amp;gt; -n &amp;lt;name&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>option#2:&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>&lt;code>kubectl cordon node&lt;/code> #make sure no scheduling on this node&lt;/li>
&lt;li>&lt;code>kubectl drain node&lt;/code> #schedule pod in current node to other node&lt;/li>
&lt;li>restart the Azure VM for node via the API or portal, wait until VM is &amp;ldquo;Running&amp;rdquo;&lt;/li>
&lt;li>&lt;code>kubectl uncordon node&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/60183">fix race condition issue when detaching azure disk&lt;/a> has fixed this issue by add a lock before DetachDisk&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.6&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="2-disk-unavailable-after-attachdetach-a-data-disk-on-a-node">2. disk unavailable after attach/detach a data disk on a node&lt;/h2>
&lt;blockquote>
&lt;p>ðŸ’¡ NOTE: Azure platform has fixed the host cache issue, the suggested host cache setting of data disk is &lt;code>ReadOnly&lt;/code> now, more details about &lt;a href="https://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching">azure disk cache setting&lt;/a>
&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;/blockquote>
&lt;p>From k8s v1.7, default host cache setting changed from &lt;code>None&lt;/code> to &lt;code>ReadWrite&lt;/code>, this change would lead to device name change after attach multiple disks on a node, finally lead to disk unavailable from pod. When access data disk inside a pod, will get following error:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>root@admin-0 /&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># ls /datadisk&lt;/span>
ls: reading directory .: Input/output error
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In my testing on Ubuntu 16.04 D2_V2 VM, when attaching the 6th data disk will cause device name change on agent node, e.g. following lun0 disk should be &lt;code>sdc&lt;/code> other than &lt;code>sdk&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">azureuser@k8s-agentpool2-40588258-0:~$ tree /dev/disk/azure
...
Ã¢â€â€Ã¢â€â‚¬Ã¢â€â‚¬ scsi1
Ã¢â€Å“Ã¢â€â‚¬Ã¢â€â‚¬ lun0 -&amp;gt; ../../../sdk
Ã¢â€Å“Ã¢â€â‚¬Ã¢â€â‚¬ lun1 -&amp;gt; ../../../sdj
Ã¢â€Å“Ã¢â€â‚¬Ã¢â€â‚¬ lun2 -&amp;gt; ../../../sde
Ã¢â€Å“Ã¢â€â‚¬Ã¢â€â‚¬ lun3 -&amp;gt; ../../../sdf
Ã¢â€Å“Ã¢â€â‚¬Ã¢â€â‚¬ lun4 -&amp;gt; ../../../sdg
Ã¢â€Å“Ã¢â€â‚¬Ã¢â€â‚¬ lun5 -&amp;gt; ../../../sdh
Ã¢â€â€Ã¢â€â‚¬Ã¢â€â‚¬ lun6 -&amp;gt; ../../../sdi
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/60344">device name change due to azure disk host cache setting&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/57444">unable to use azure disk in StatefulSet since /dev/sd* changed after detach/attach disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/201">Disk error when pods are mounting a certain amount of volumes on a node&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/1918">unable to use azure disk in StatefulSet since /dev/sd* changed after detach/attach disk&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/297">Input/output error when accessing PV&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/ACS/issues/113">PersistentVolumeClaims changing to Read-only file system suddenly&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>add &lt;code>cachingmode: None&lt;/code> in azure disk storage class(default is &lt;code>ReadWrite&lt;/code>), e.g.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">StorageClass&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">apiVersion&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">storage.k8s.io/v1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">metadata&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">hdd&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">provisioner&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">kubernetes.io/azure-disk&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">parameters&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">skuname&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Standard_LRS&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Managed&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">cachingmode&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">None&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/60346">fix device name change issue for azure disk&lt;/a> could fix this issue too, it will change default &lt;code>cachingmode&lt;/code> value from &lt;code>ReadWrite&lt;/code> to &lt;code>None&lt;/code>.&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.6&lt;/td>
&lt;td>no such issue as &lt;code>cachingmode&lt;/code> is already &lt;code>None&lt;/code> by default&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="3-azure-disk-support-on-sovereign-cloud">3. Azure disk support on Sovereign Cloud&lt;/h2>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/50673">Azure disk on Sovereign Cloud&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="4-time-cost-for-azure-disk-pvc-mount">4. Time cost for Azure Disk PVC mount&lt;/h2>
&lt;p>Original time cost for Azure Disk PVC mount on a standard node size(e.g. Standard_D2_V2) is around 1 minute, &lt;code>podAttachAndMountTimeout&lt;/code> is &lt;a href="https://github.com/kubernetes/kubernetes/blob/b812eaa172804739283e6e8723cbca3ed293e7ff/pkg/kubelet/volumemanager/volume_manager.go#L78">2 minutes&lt;/a>, total &lt;code>waitForAttachTimeout&lt;/code> is &lt;a href="https://github.com/kubernetes/kubernetes/blob/b812eaa172804739283e6e8723cbca3ed293e7ff/pkg/kubelet/volumemanager/volume_manager.go#L86">10 minutes&lt;/a>, so a disk remount(detach and attach in sequential) would possibly cost more than 2min, thus may fail.&lt;/p>
&lt;blockquote>
&lt;p>Note: for some smaller VM size which has only 1 CPU core, time cost would be much bigger(e.g. &amp;gt; 10min) since container is hard to get CPU slot.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/166">&amp;lsquo;timeout expired waiting for volumes to attach/mount for pod when cluster&amp;rsquo; when node-vm-size is Standard_B1s&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/57432">using cache fix&lt;/a> fixed this issue, which could reduce the mount time cost to around 30s.&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="5-azure-disk-pvc-multi-attach-error-makes-disk-mount-very-slow-or-mount-failure-forever">5. Azure disk PVC &lt;code>Multi-Attach error&lt;/code>, makes disk mount very slow or mount failure forever&lt;/h2>
&lt;blockquote>
&lt;p>ðŸ’¡ NOTE: AKS and current aks-engine won&amp;rsquo;t have this issue since it&amp;rsquo;s &lt;strong>not&lt;/strong> using containerized kubelet&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When schedule a pod with azure disk volume from one node to another, total time cost of detach &amp;amp; attach is around 1 min from v1.9.2, while in v1.9.x, there is an &lt;a href="https://github.com/kubernetes/kubernetes/issues/62282">UnmountDevice failure issue in containerized kubelet&lt;/a> which makes disk mount very slow or mount failure forever, this issue only exists in v1.9.x due to PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/51771">Refactor nsenter&lt;/a>, v1.10.0 won&amp;rsquo;t have this issue since &lt;code>devicePath&lt;/code> is updated in &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.10/pkg/volume/util/operationexecutor/operation_generator.go#L1130-L1131">v1.10 code&lt;/a>&lt;/p>
&lt;p>&lt;strong>error logs&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>kubectl describe po POD-NAME&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Normal Scheduled 3m default-scheduler Successfully assigned deployment-azuredisk1-6cd8bc7945-kbkvz to k8s-agentpool-88970029-0
Warning FailedAttachVolume 3m attachdetach-controller Multi-Attach error &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volume &lt;span style="color:#4e9a06">&amp;#34;pvc-6f2d0788-3b0b-11e8-a378-000d3afe2762&amp;#34;&lt;/span> Volume is already exclusively attached to one node and can&lt;span style="color:#a40000">&amp;#39;&lt;/span>t be attached to another
Normal SuccessfulMountVolume 3m kubelet, k8s-agentpool-88970029-0 MountVolume.SetUp succeeded &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volume &lt;span style="color:#4e9a06">&amp;#34;default-token-qt7h6&amp;#34;&lt;/span>
Warning FailedMount 1m kubelet, k8s-agentpool-88970029-0 Unable to mount volumes &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> pod &lt;span style="color:#4e9a06">&amp;#34;deployment-azuredisk1-6cd8bc7945-kbkvz_default(5346c040-3e4c-11e8-a378-000d3afe2762)&amp;#34;&lt;/span>: timeout expired waiting &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volumes to attach/mount &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> pod &lt;span style="color:#4e9a06">&amp;#34;default&amp;#34;&lt;/span>/&lt;span style="color:#4e9a06">&amp;#34;deployment-azuredisk1-6cd8bc7945-kbkvz&amp;#34;&lt;/span>. list of unattached/unmounted &lt;span style="color:#000">volumes&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=[&lt;/span>azuredisk&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>kubelet logs from the new node&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">E0412 20:08:10.920284 &lt;span style="color:#0000cf;font-weight:bold">7602&lt;/span> nestedpendingoperations.go:263&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Operation &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;\&amp;#34;kubernetes.io/azure-disk//subscriptions/xxx/resourceGroups/MC_xxx_eastus/providers/Microsoft.Compute/disks/kubernetes-dynamic-pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34;&amp;#34;&lt;/span> failed. No retries permitted &lt;span style="color:#204a87;font-weight:bold">until&lt;/span> 2018-04-12 20:08:12.920234762 +0000 UTC &lt;span style="color:#000">m&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>+1467.278612421 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>durationBeforeRetry 2s&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>. Error: &lt;span style="color:#4e9a06">&amp;#34;Volume has not been added to the list of VolumesInUse in the node&amp;#39;s volume status for volume \&amp;#34;pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34; (UniqueName: \&amp;#34;kubernetes.io/azure-disk//subscriptions/xxx/resourceGroups/MC_xxx_eastus/providers/Microsoft.Compute/disks/kubernetes-dynamic-pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34;) pod \&amp;#34;symbiont-node-consul-0\&amp;#34; (UID: \&amp;#34;11043b12-3e8d-11e8-82ec-0a58ac1f04cf\&amp;#34;) &amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/62282">UnmountDevice would fail in containerized kubelet&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2022">upgrade k8s process is broke&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Mitigation&lt;/strong>:&lt;/p>
&lt;p>If azure disk PVC mount successfully in the end, there is no action, while if it could not be mounted for more than 20min, following actions could be taken:&lt;/p>
&lt;ul>
&lt;li>check whether &lt;code>volumesInUse&lt;/code> list has unmounted azure disks, run:&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>kubectl get no NODE-NAME -o yaml &amp;gt; node.log
&lt;/code>&lt;/pre>&lt;p>all volumes in &lt;code>volumesInUse&lt;/code> should be also in &lt;code>volumesAttached&lt;/code>, otherwise there would be issue&lt;/p>
&lt;ul>
&lt;li>restart kubelet on the original node would solve this issue: &lt;code>sudo kubectl kubelet restart&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/62467">fix nsenter GetFileType issue in containerized kubelet&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>v1.9.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>After fix in v1.9.7, it took about 1 minute for scheduling one azure disk mount from one node to another, you could find details &lt;a href="https://github.com/kubernetes/kubernetes/issues/62282#issuecomment-380794459">here&lt;/a>.&lt;/p>
&lt;p>Since azure disk attach/detach operation on a VM cannot be parallel, scheduling 3 azure disk mounts from one node to another would cost about 3 minutes.&lt;/p>
&lt;h2 id="6-waitforattach-failed-for-azure-disk-parsing-devdiskazurescsi1lun1-invalid-syntax">6. WaitForAttach failed for azure disk: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun1&amp;rdquo;: invalid syntax&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
MountVolume.WaitForAttach may fail in the azure disk remount&lt;/p>
&lt;p>&lt;strong>error logs&lt;/strong>:&lt;/p>
&lt;p>in v1.10.0 &amp;amp; v1.10.1, &lt;code>MountVolume.WaitForAttach&lt;/code> will fail in the azure disk remount, error logs would be like following:&lt;/p>
&lt;ul>
&lt;li>incorrect &lt;code>DevicePath&lt;/code> format on Linux&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>MountVolume.WaitForAttach failed for volume &amp;quot;pvc-f1562ecb-3e5f-11e8-ab6b-000d3af9f967&amp;quot; : azureDisk - Wait for attach expect device path as a lun number, instead got: /dev/disk/azure/scsi1/lun1 (strconv.Atoi: parsing &amp;quot;/dev/disk/azure/scsi1/lun1&amp;quot;: invalid syntax)
Warning FailedMount 1m (x10 over 21m) kubelet, k8s-agentpool-66825246-0 Unable to mount volumes for pod
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>wrong &lt;code>DevicePath&lt;/code>(LUN) number on Windows&lt;/li>
&lt;/ul>
&lt;pre>&lt;code> Warning FailedMount 1m kubelet, 15282k8s9010 MountVolume.WaitForAttach failed for volume &amp;quot;disk01&amp;quot; : azureDisk - WaitForAttach failed within timeout node (15282k8s9010) diskId:(andy-mghyb
1102-dynamic-pvc-6c526c51-4a18-11e8-ab5c-000d3af7b38e) lun:(4)
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/62540">WaitForAttach failed for azure disk: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun1&amp;rdquo;: invalid syntax&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2906">Pod unable to attach PV after being deleted (Wait for attach expect device path as a lun number, instead got: /dev/disk/azure/scsi1/lun0 (strconv.Atoi: parsing &amp;ldquo;/dev/disk/azure/scsi1/lun0&amp;rdquo;: invalid syntax)&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/62612">fix WaitForAttach failure issue for azure disk&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.2&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="7-uid-and-gid-setting-in-azure-disk">7. &lt;code>uid&lt;/code> and &lt;code>gid&lt;/code> setting in azure disk&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
Unlike azure file mountOptions, you will get following failure if set &lt;code>mountOptions&lt;/code> like &lt;code>uid=999,gid=999&lt;/code> in azure disk mount:&lt;/p>
&lt;pre>&lt;code>Warning FailedMount 63s kubelet, aks-nodepool1-29460110-0 MountVolume.MountDevice failed for volume &amp;quot;pvc-d783d0e4-85a1-11e9-8a90-369885447933&amp;quot; : azureDisk - mountDevice:FormatAndMount failed with mount failed: exit status 32
Mounting command: systemd-run
Mounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/plugins/kubernetes.io/azure-disk/mounts/m436970985 --scope -- mount -t xfs -o dir_mode=0777,file_mode=0777,uid=1000,gid=1000,defaults /dev/disk/azure/scsi1/lun2 /var/lib/kubelet/plugins/kubernetes.io/azure-disk/mounts/m436970985
Output: Running scope as unit run-rb21966413ab449b3a242ae9b0fbc9398.scope.
mount: wrong fs type, bad option, bad superblock on /dev/sde,
missing codepage or helper program, or other error
&lt;/code>&lt;/pre>&lt;p>That&amp;rsquo;s because azureDisk use ext4,xfs file system by default, mountOptions like [uid=x,gid=x] could not be set in mount time.&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/67014#issuecomment-589915496">Timeout expired waiting for volumes to attach&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/1030">Pod failed mounting xfs format volume with mountOptions&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/69699#issuecomment-558861917">Allow volume ownership to be only set after fs formatting&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Solution&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>option#1: Set uid in &lt;code>runAsUser&lt;/code> and gid in &lt;code>fsGroup&lt;/code> for pod: &lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">security context for a Pod&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>e.g. Following setting will set pod run as root, make it accessible to any file:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">apiVersion&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">v1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Pod&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">metadata&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">security-context-demo&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">spec&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">securityContext&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">runAsUser&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">fsGroup&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>Note: Since gid &amp;amp; uid is mounted as 0(root) by default, if set as non-root(e.g. 1000), k8s will use chown to change all dir/files under that disk, this is a time consuming job, which would make mount device very slow, in this issue: &lt;a href="https://github.com/kubernetes/kubernetes/issues/67014#issuecomment-413546283">Timeout expired waiting for volumes to attach&lt;/a>, it costs about 10 min for chown operation complete.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>option#2: use &lt;code>chown&lt;/code> in &lt;code>initContainers&lt;/code>&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>initContainers:
- name: volume-mount
image: busybox
command: [&amp;quot;sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;chown -R 100:100 /data&amp;quot;]
volumeMounts:
- name: &amp;lt;your data volume&amp;gt;
mountPath: /data
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>new upstream feature to address this: &lt;a href="https://github.com/kubernetes/kubernetes/issues/69699">Allow volume ownership to be only set after fs formatting&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="8-addition-of-a-blob-based-disk-to-vm-with-managed-disks-is-not-supported">8. &lt;code>Addition of a blob based disk to VM with managed disks is not supported&lt;/code>&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>Following error may occur if attach a blob based(unmanaged) disk to VM with managed disks:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh"> Warning FailedMount 42s &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>x2 over 1m&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> attachdetach AttachVolume.Attach failed &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> volume &lt;span style="color:#4e9a06">&amp;#34;pvc-f17e5e77-474e-11e8-a2ea-000d3a10df6d&amp;#34;&lt;/span> : Attach volume &lt;span style="color:#4e9a06">&amp;#34;holo-k8s-dev-dynamic-pvc-f17e5e77-474e-11e8-a2ea-000d3a10df6d&amp;#34;&lt;/span> to instance &lt;span style="color:#4e9a06">&amp;#34;k8s-master-92699158-0&amp;#34;&lt;/span> failed with compute.VirtualMachinesClient#CreateOrUpdate: Failure responding to request: &lt;span style="color:#000">StatusCode&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> -- Original Error: autorest/azure: Service returned an error. &lt;span style="color:#000">Status&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> &lt;span style="color:#000">Code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;OperationNotAllowed&amp;#34;&lt;/span> &lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;Addition of a blob based disk to VM with managed disks is not supported.&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This issue is by design as in Azure, there are two kinds of disks, blob based(unmanaged) disk and managed disk, an Azure VM could not attach both of these two kinds of disks.&lt;/p>
&lt;p>&lt;strong>Solution&lt;/strong>:&lt;/p>
&lt;p>Use &lt;code>default&lt;/code> azure disk storage class in acs-engine, as &lt;code>default&lt;/code> will always be identical to the agent pool, that is, if VM is managed, it will be managed azure disk class, if unmanaged, then it&amp;rsquo;s unmanaged disk class.&lt;/p>
&lt;h2 id="9-dynamic-azure-disk-pvc-try-to-access-wrong-storage-account-of-other-resource-group">9. dynamic azure disk PVC try to access wrong storage account (of other resource group)&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>In a k8s cluster with &lt;strong>blob based&lt;/strong> VMs(won&amp;rsquo;t happen in AKS since AKS only use managed disk), create dynamic azure disk PVC may fail, error logs is like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;default&amp;#34;&lt;/span>: azureDisk - account ds6c822a4d484211eXXXXXX does not exist &lt;span style="color:#204a87;font-weight:bold">while&lt;/span> trying to create/ensure default container
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/acs-engine/issues/2768">Multiple clusters - dynamic PVCs try to access wrong storage account (of other resource group)&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/56474">fix storage account not found issue: use ListByResourceGroup instead of List()&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.13&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>this bug only exists in blob based VM in v1.8.x, v1.9.x, so if specify &lt;code>ManagedDisks&lt;/code> when creating k8s cluster in acs-engine(AKS is using managed disk by default), it won&amp;rsquo;t have this issue:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json"> &lt;span style="color:#4e9a06">&amp;#34;agentPoolProfiles&amp;#34;&lt;/span>&lt;span style="color:#a40000">:&lt;/span> &lt;span style="color:#000;font-weight:bold">[&lt;/span>
&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#a40000">...&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">&amp;#34;storageProfile&amp;#34;&lt;/span> &lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;ManagedDisks&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#a40000">...&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="10-data-loss-if-using-existing-azure-disk-with-partitions-in-disk-mount">10. data loss if using existing azure disk with partitions in disk mount&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When use an existing azure disk(also called &lt;a href="https://github.com/andyzhangx/demo/tree/master/linux/azuredisk#static-provisioning-for-azure-disk">static provisioning&lt;/a>) in pod, if that disk has partitions, the disk will be formatted in the pod mounting process, actually k8s volume don&amp;rsquo;t support mount disk with partitions, disk mount would fail finally. While for mounting existing &lt;strong>azure&lt;/strong> disk that has partitions, data will be lost since it will format that disk first. This issue happens only on &lt;strong>Linux&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/63235">data loss if using existing azure disk with partitions in disk mount&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/63270">fix data loss issue if using existing azure disk with partitions in disk mount&lt;/a> will let azure provider return error when mounting existing azure disk that has partitions&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.15&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Don&amp;rsquo;t use existing azure disk that has partitions, e.g. following disk in LUN 0 that has one partition:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">azureuser@aks-nodepool1-28371372-0:/$ ls -l /dev/disk/azure/scsi1/
total &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
lrwxrwxrwx &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> root root &lt;span style="color:#0000cf;font-weight:bold">12&lt;/span> Apr &lt;span style="color:#0000cf;font-weight:bold">27&lt;/span> 08:04 lun0 -&amp;gt; ../../../sdc
lrwxrwxrwx &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> root root &lt;span style="color:#0000cf;font-weight:bold">13&lt;/span> Apr &lt;span style="color:#0000cf;font-weight:bold">27&lt;/span> 08:04 lun0-part1 -&amp;gt; ../../../sdc1
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="11-delete-azure-disk-pvc-which-is-already-in-use-by-a-pod">11. Delete azure disk PVC which is already in use by a pod&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>Following error may occur if delete azure disk PVC which is already in use by a pod:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubectl describe pv pvc-d8eebc1d-74d3-11e8-902b-e22b71bb1c06
...
Message: disk.DisksClient#Delete: Failure responding to request: &lt;span style="color:#000">StatusCode&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> -- Original Error: autorest/azure: Service returned an error. &lt;span style="color:#000">Status&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">409&lt;/span> &lt;span style="color:#000">Code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;OperationNotAllowed&amp;#34;&lt;/span> &lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;Disk kubernetes-dynamic-pvc-d8eebc1d-74d3-11e8-902b-e22b71bb1c06 is attached to VM /subscriptions/{subs-id}/resourceGroups/MC_markito-aks-pvc_markito-aks-pvc_westus/providers/Microsoft.Compute/virtualMachines/aks-agentpool-25259074-0.&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>:&lt;/p>
&lt;p>This is a common k8s issue, other cloud provider would also has this issue. There is a &lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/pvc-protection/">PVC protection&lt;/a> feature to prevent this, it&amp;rsquo;s alpha in v1.9, and beta(enabled by default) in v1.10&lt;/p>
&lt;p>&lt;strong>Work around&lt;/strong>:
delete pod first and then delete azure disk pvc after a few minutes&lt;/p>
&lt;h2 id="12-create-azure-disk-pvc-failed-due-to-account-creation-failure">12. create azure disk PVC failed due to account creation failure&lt;/h2>
&lt;blockquote>
&lt;p>please note this issue only happens on &lt;strong>unmanaged&lt;/strong> k8s cluster&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Issue details&lt;/strong>: User may get &lt;code>Account property kind is invalid for the request&lt;/code> error when trying to create a new &lt;strong>unmanaged&lt;/strong> azure disk PVC, error would be like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">azureuser@k8s-master-17140924-0:/tmp$ kubectl describe pvc
Name: pvc-azuredisk
Namespace: default
StorageClass: hdd
Status: Bound
...
Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Warning ProvisioningFailed 31m persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;hdd&amp;#34;&lt;/span>: Create Storage Account: ds10e15ed89c5811e8a0a70, error: storage.AccountsClient#Create: Failure sending request: &lt;span style="color:#000">StatusCode&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">400&lt;/span> -- Original Error: &lt;span style="color:#000">Code&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;AccountPropertyIsInvalid&amp;#34;&lt;/span> &lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;Account property kind is invalid for the request.&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/67236">fix azure disk create failure due to sdk upgrade&lt;/a> fixed this issue&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>create a storage account and specify that account in azure disk storage class, e.g.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">StorageClass&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">apiVersion&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">storage.k8s.io/v1beta1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">metadata&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">ssd&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">provisioner&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">kubernetes.io/azure-disk&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">parameters&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">skuname&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Premium_LRS&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">storageAccount&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">customerstorageaccount&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Dedicated&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="13-cannot-find-lun-for-disk">13. cannot find Lun for disk&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>Following error may occur if attach a disk to a node:&lt;/p>
&lt;pre>&lt;code>MountVolume.WaitForAttach failed for volume &amp;quot;pvc-12b458f4-c23f-11e8-8d27-46799c22b7c6&amp;quot; : Cannot find Lun for disk kubernetes-dynamic-pvc-12b458f4-c23f-11e8-8d27-46799c22b7c6
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/69262">GetAzureDiskLun sometimes costs 1 min which is too long time&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/70002">fix azure disk attachment error on Linux&lt;/a> will extract the LUN num from device path &lt;strong>only on Linux&lt;/strong>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>wait for a few more minutes should work&lt;/p>
&lt;h2 id="14-azure-disk-attachdetach-failure-mount-issue-io-error">14. azure disk attach/detach failure, mount issue, i/o error&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>We found a disk attach/detach issue due to &lt;a href="https://github.com/kubernetes/kubernetes/pull/58313">dirty vm cache PR&lt;/a> introduced from v1.9.2, it would lead to following disk issues:&lt;/p>
&lt;ul>
&lt;li>disk attach/detach failure for a long time&lt;/li>
&lt;li>disk I/O error&lt;/li>
&lt;li>unexpected disk detachment from VM&lt;/li>
&lt;li>VM running into failed state due to attaching non-existing disk&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Note: above error may &lt;strong>only&lt;/strong> happen when there are multiple disk attach/detach operations in parallel and it&amp;rsquo;s not easy to repro since it happens on a little possibility.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/71344">Azure Disks volume attach still times out on Kubernetes 1.10&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/71453">Azure Disks occasionally mounted in a way leading to I/O errors&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;p>We changed the azure disk attach/detach retry logic in k8s v1.13, switch to use k8s attach-detach controller to do attach/detach disk retry and clean vm cache after every disk operation, this issue is proved to be fixed in our disk attach/detach stress test and also verified in customer env:&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/70568">remove retry operation on attach/detach azure disk in azure cloud provider&lt;/a>&lt;/li>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/71377">fix azure disk attach/detach failed forever issue&lt;/a>&lt;/li>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/71495">fix detach azure disk issue due to dirty cache&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>issue introduced in v1.9.2, no cherry-pick fix allowed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.12&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no such issue&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>if there is attach disk failure for long time, restart controller manager may work&lt;/li>
&lt;li>if there is disk not detached for long time, detach that disk manually&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/477">Multi Attach Error&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="15-azure-disk-could-be-not-detached-forever">15. azure disk could be not detached forever&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>In some condition when first detach azure disk operation failed, it won&amp;rsquo;t retry and the azure disk would be still attached to the original VM node.&lt;/p>
&lt;p>Following error may occur when move one disk from one node to another(keyword: &lt;code>ConflictingUserInput&lt;/code>):&lt;/p>
&lt;pre>&lt;code>[Warning] AttachVolume.Attach failed for volume â€œpvc-7b7976d7-3a46-11e9-93d5-dee1946e6ce9â€ : Attach volume â€œkubernetes-dynamic-pvc-7b7976d7-3a46-11e9-93d5-dee1946e6ce9&amp;quot; to instance â€œ/subscriptions/XXX/resourceGroups/XXX/providers/Microsoft.Compute/virtualMachines/aks-agentpool-57634498-0â€ failed with compute.VirtualMachinesClient#CreateOrUpdate: Failure sending request: StatusCode=0 -- Original Error: autorest/azure: Service returned an error. Status= Code=â€œConflictingUserInputâ€ Message=â€œDisk â€˜/subscriptions/XXX/resourceGroups/XXX/providers/Microsoft.Compute/disks/kubernetes-dynamic-pvc-7b7976d7-3a46-11e9-93d5-dee1946e6ce9â€™ cannot be attached as the disk is already owned by VM â€˜/subscriptions/XXX/resourceGroups/XXX/providers/Microsoft.Compute/virtualMachines/aks-agentpool-57634498-1â€™.â€
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;p>We added retry logic for detach azure disk:&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/74398">add retry for detach azure disk&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>N/A&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>if there is disk not detached for long time, detach that disk manually&lt;/li>
&lt;/ul>
&lt;h2 id="16-potential-race-condition-issue-due-to-detach-disk-failure-retry">16. potential race condition issue due to detach disk failure retry&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>In some error condition when detach azure disk failed, azure cloud provider will retry 6 times at most with exponential backoff, it will hold the data disk list for about 3 minutes with a node level lock, and in that time period, if customer update data disk list manually (e.g. need manual operationto attach/detach another disk since there is attach/detach error, ) , the data disk list will be obselete(dirty data), then weird VM status happens, e.g. attach a non-existing disk, we should split those retry operations, every retry should get a fresh data disk list in the beginning.&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;p>Following PR refined detach azure disk retry operation, make every detach azure disk operation in a standalone function&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/76573">fix detach azure disk back off issue which has too big lock in failure retry condition&lt;/a>&lt;/li>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/77187">fix azure disk list corruption issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>N/A&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Detach all the non-existing disks from VM (could do that in azure portal by bulk update)&lt;/p>
&lt;blockquote>
&lt;p>Detaching disk one by one using cli may fail since they are already non-existing disks.&lt;/p>
&lt;/blockquote>
&lt;h2 id="17-very-slow-disk-attachdetach-issue-when-disk-num-is-large">17. very slow disk attach/detach issue when disk num is large&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>We hit very slow disk attach/detach issue when disk num is large(&amp;gt; 10 disks on one VM)&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;p>Azure disk team are fixing this issue.&lt;/p>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>No workaround.&lt;/p>
&lt;h2 id="18-detach-azure-disk-make-vm-run-into-a-limbo-state">18. detach azure disk make VM run into a limbo state&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>In some corner condition, detach azure disk would sometimes make VM run into a limbo state&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;p>Following two PRs would fix this issue by retry update VM if detach disk partially fail:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/78298">fix azure retry issue when return 2XX with error&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/78700">fix: retry detach azure disk issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Update VM status manually would solve the problem:&lt;/p>
&lt;ul>
&lt;li>Update Availability Set VM&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>az vm update -n &amp;lt;VM_NAME&amp;gt; -g &amp;lt;RESOURCE_GROUP_NAME&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Update Scale Set VM&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>az vmss update-instances -g &amp;lt;RESOURCE_GROUP_NAME&amp;gt; --name &amp;lt;VMSS_NAME&amp;gt; --instance-id &amp;lt;ID(number)&amp;gt;
&lt;/code>&lt;/pre>&lt;h2 id="19-disk-attachdetach-self-healing-on-vmas">19. disk attach/detach self-healing on VMAS&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
There could be disk detach failure due to many reasons(e.g. disk RP busy, controller manager crash, etc.), and it would fail when attach one disk to other node if that disk is still attached to the old node, user needs to manually detach disk in problem in the before, with this fix, azure cloud provider would check and detach this disk if it&amp;rsquo;s already attached to the other node, that&amp;rsquo;s like self-healing. This PR could fix lots of such disk attachment issue.&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;p>Following PR would first check whether current disk is already attached to other node, if so, it would trigger a dangling error and k8s controller would detach disk first, and then do the attach volume operation.&lt;/p>
&lt;p>This PR would also fix a &amp;ldquo;disk not found&amp;rdquo; issue when detach azure disk due to disk URI case sensitive case, error logs are like following(without this PR):&lt;/p>
&lt;pre>&lt;code>azure_controller_standard.go:134] detach azure disk: disk not found, diskURI: /subscriptions/xxx/resourceGroups/andy-mg1160alpha3/providers/Microsoft.Compute/disks/xxx-dynamic-pvc-41a31580-f5b9-4f08-b0ea-0adcba15b6db
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Fix on VMAS
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/81266">fix: detach azure disk issue using dangling error&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/81720">fix: azure disk name matching issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.16.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>Fix on VMSS
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/90749">fix: azure disk dangling attach issue on VMSS which would cause API throttling&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.18&lt;/td>
&lt;td>1.18.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.19&lt;/td>
&lt;td>1.19.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>manually detach disk in problem and wait for disk attachment happen automatically&lt;/p>
&lt;h2 id="20-azure-disk-detach-failure-if-node-not-exists">20. azure disk detach failure if node not exists&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
If a node with a Azure Disk attached is deleted (before the volume is detached), subsequent attempts by the attach/detach controller to detach it continuously fail, and prevent the controller from attaching the volume to another node.&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/82640">fix: azure disk detach failure if node not exists&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.17.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Restart kube-controller-manager on master node.&lt;/p>
&lt;h2 id="21-invalid-disk-uri-error">21. invalid disk URI error&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When user use an existing disk in static provisioning, may hit following error:&lt;/p>
&lt;pre>&lt;code>AttachVolume.Attach failed for volume &amp;quot;azure&amp;quot; : invalid disk URI: /subscriptions/xxx/resourcegroups/xxx/providers/Microsoft.Compute/disks/Test_Resize_1/â€
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/79020">fix: make azure disk URI as case insensitive&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Use &lt;code>resourceGroups&lt;/code> instead of &lt;code>resourcegroups&lt;/code> in disk PV configuration&lt;/p>
&lt;h2 id="22-vmss-dirty-cache-issue">22. vmss dirty cache issue&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>clean vmss cache should happen after disk attach/detach operation, now it&amp;rsquo;s before those operations, which would lead to dirty cache.
since update operation may cost 30s or more, and at that time period, if there is another get vmss operation, it would get the old data disk list&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/aks-engine/issues/2312">VMSS disk attach/detach issues w/ v1.13.12, v1.14.8, v1.15.5, v1.16.2&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/1278">Disk attachment/mounting problems, all pods with PVCs stuck in ContainerCreating&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/85158">fix vmss dirty cache issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;th>notes&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no fix&lt;/td>
&lt;td>regression since 1.13.12 (hotfixed in AKS release)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.10&lt;/td>
&lt;td>regression only in 1.14.8, 1.14.9 (hotfixed in AKS release)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.7&lt;/td>
&lt;td>regression only in 1.15.5, 1.15.6 (hotfixed in AKS release)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.4&lt;/td>
&lt;td>regression only in 1.16.2, 1.16.3 (hotfixed in AKS release)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.0&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Detach disk in problem manually&lt;/p>
&lt;h2 id="23-race-condition-when-delete-disk-right-after-attach-disk">23. race condition when delete disk right after attach disk&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>There is condition that attach and delete disk happens in same time, azure CRP don&amp;rsquo;t check such race condition&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/82714">should not delete an azure disk when that disk is being attached&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/84917">fix race condition when delete azure disk right after attach azure disk&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;th>notes&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no fix&lt;/td>
&lt;td>hotfixed in AKS release since 1.13.12&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.10&lt;/td>
&lt;td>hotfixed in AKS release in 1.14.8, 1.14.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.7&lt;/td>
&lt;td>hotfixed in AKS release in 1.15.5, 1.15.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.4&lt;/td>
&lt;td>hotfixed in AKS release in 1.16.2, 1.16.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.0&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Detach disk in problem manually&lt;/p>
&lt;h2 id="24-attach-disk-costs-10min">24. attach disk costs 10min&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/83102">Fix aggressive VM calls for Azure VMSS&lt;/a> change getVMSS cache TTL from 1min to 10min, getVMAS cache TTL from 5min to 10min, that will cause error &lt;code>WaitForAttach ... Cannot find Lun for disk&lt;/code>, and it would make attach disk opeation costs 10min on VMSS and 15min on VMAS, detailed error would be like following:&lt;/p>
&lt;pre>&lt;code>Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Normal Scheduled 29m default-scheduler Successfully assigned authentication/authentication-mssql-statefulset-0 to aks-nodepool1-29122124-vmss000004
Normal SuccessfulAttachVolume 28m attachdetach-controller AttachVolume.Attach succeeded for volume &amp;quot;pvc-8d9f0ade-1825-11ea-83a0-22ced17d4a3d&amp;quot;
Warning FailedMount 23m (x10 over 27m) kubelet, aks-nodepool1-29122124-vmss000004 MountVolume.WaitForAttach failed for volume &amp;quot;pvc-8d9f0ade-1825-11ea-83a0-22ced17d4a3d&amp;quot; : Cannot find Lun for disk kubernetes-dynamic-pvc-8d9f0ade-1825-11ea-83a0-22ced17d4a3d
Warning FailedMount 23m (x3 over 27m) kubelet, aks-nodepool1-29122124-vmss000004 Unable to mount volumes for pod &amp;quot;authentication-mssql-statefulset-0_authentication(8df467e7-1825-11ea-83a0-22ced17d4a3d)&amp;quot;: timeout expired waiting for volumes to attach or mount for pod &amp;quot;authentication&amp;quot;/&amp;quot;authentication-mssql-statefulset-0&amp;quot;. list of unmounted volumes=[authentication-mssql-persistent-data-storage]. list of unattached volumes=[authentication-mssql-persistent-data-storage default-token-b7spv]
Normal Pulled 21m kubelet, aks-nodepool1-29122124-vmss000004 Container image &amp;quot;mcr.microsoft.com/mssql/server:2019-CTP3.2-ubuntu&amp;quot; already present on machine
Normal Created 21m kubelet, aks-nodepool1-29122124-vmss000004 Created container authentication-mssql
Normal Started 21m kubelet, aks-nodepool1-29122124-vmss000004 Started container authentication-mssql
&lt;/code>&lt;/pre>&lt;p>This slow disk attachment issue only exists on &lt;code>1.13.12+&lt;/code>, &lt;code>1.14.8+&lt;/code>, fortunately, from k8s 1.15.0, this issue won&amp;rsquo;t happen, since getDiskLUN logic has already been refactored (already has PR:&lt;a href="https://github.com/kubernetes/kubernetes/pull/77912">fix azure disk lun error&lt;/a>, won&amp;rsquo;t depend on getVMSS operation to get disk LUN.&lt;/p>
&lt;p>&lt;strong>Relate issues&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/69262#issuecomment-562567413">GetAzureDiskLun sometimes costs 10min which is too long time&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/77912">fix azure disk lun error&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;th>notes&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>no fix&lt;/td>
&lt;td>need to hotfix in AKS release since 1.13.12 (slow disk attachment exists on &lt;code>1.13.12+&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>in cherry-pick&lt;/td>
&lt;td>need to hotfix in AKS release in 1.14.8, 1.14.9 (slow disk attachment exists on &lt;code>1.14.8+&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.0&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.0&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Wait for about 10min or 15min, &lt;code>MountVolume.WaitForAttach&lt;/code> operation would retry and would finally succeed&lt;/p>
&lt;h2 id="25-multi-attach-error">25. Multi-Attach error&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>If two pods on different nodes are using same disk PVC(this issue may also happen when doing rollingUpdate in Deployment using one replica), would probably hit following error:&lt;/p>
&lt;pre>&lt;code>Events:
Warning FailedAttachVolume 9m attachdetach-controller Multi-Attach error for volume &amp;quot;pvc-fc0bed38-48bf-43f1-a7e4-255eef48ffb9&amp;quot; Volume is already used by pod(s) sqlserver3-5b8449449-5chzx
Warning FailedMount 42s (x4 over 7m) kubelet, aks-nodepool1-15915763-vmss000001 Unable to mount volumes for pod &amp;quot;sqlserver3-55754785bb-jjr6d_default(55381f38-9640-43a9-888d-096387cbb780)&amp;quot;: timeout expired waiting for volumes to attach or mount for pod &amp;quot;default&amp;quot;/&amp;quot;sqlserver3-55754785bb-jjr6d&amp;quot;. list of unmounted volumes=[mssqldb]. list of unattached volumes=[mssqldb default-token-q7cw9]
&lt;/code>&lt;/pre>&lt;p>The above issue is upstream issue(&lt;a href="https://github.com/kubernetes/kubernetes/blob/20c265fef0741dd71a66480e35bd69f18351daea/pkg/controller/volume/attachdetach/reconciler/reconciler.go#L351">detailed error code&lt;/a>), it could be due to following reasons:&lt;/p>
&lt;ul>
&lt;li>two pods are using same disk PVC, this issue could happen even using &lt;code>Deployment&lt;/code> with one replica(see below workaround)&lt;/li>
&lt;li>one node is in Shutdown(deallocated) state, this is by design now and there is on-going upstream work to fix this issue
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/58635">Propose to taint node &amp;ldquo;shutdown&amp;rdquo; condition&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/enhancements/pull/1116">add node shutdown KEP&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;ul>
&lt;li>workaround: user could use set &lt;code>terminationGracePeriodSeconds: 0&lt;/code> in deployment or &lt;code>kubectl delete pod PODNAME --grace-period=0 --force&lt;/code> to delete pod on the deallocated node&lt;/li>
&lt;li>Azure cloud provider solution: delete shutdown node(in &lt;code>InstanceExistsByProviderID&lt;/code>) like what &lt;a href="https://github.com/kubernetes/kubernetes/blob/d8febccacfc9d51a017be9531247689e0e36df04/staging/src/k8s.io/legacy-cloud-providers/aws/aws.go#L1623-L1627">other cloud provider does today&lt;/a>, while it may lead to other problem(e.g. node label loss), see details: &lt;a href="https://github.com/kubernetes/kubernetes/issues/46442">Common handling of stopped instances across cloud providers.
&lt;/a>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>since azure disk PVC could not be attached to one node.&lt;/p>
&lt;p>&lt;strong>Relate issues&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/884#issuecomment-571165826">Trouble attaching volume&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>When using disk PVC config in deployment, &lt;code>maxSurge: 0&lt;/code> could make sure there would not be no more than two pods in &lt;code>Running/ContainerCreating&lt;/code> state when doing rollingUpdate:&lt;/p>
&lt;pre>&lt;code>template:
...
strategy:
rollingUpdate:
maxSurge: 0
maxUnavailable: 1
type: RollingUpdate
&lt;/code>&lt;/pre>&lt;p>Refer to &lt;a href="https://tachingchen.com/blog/kubernetes-rolling-update-with-deployment/">Rolling Updates with Kubernetes Deployments&lt;/a> for more detailed rollingUpdate config, and you could find &lt;code>maxSurge: 0&lt;/code> setting example &lt;a href="https://github.com/andyzhangx/demo/blob/c3199932c4c00ca1095481e845642a0ec4bda598/linux/azuredisk/attach-stress-test/deployment/deployment-azuredisk1.yaml#L45-L49">here&lt;/a>&lt;/p>
&lt;p>&lt;strong>Note&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>error messages:
&lt;ul>
&lt;li>&lt;code>Multi-Attach error for volume &amp;quot;pvc-e9b72e86-129a-11ea-9a02-9abdbf393c78&amp;quot; Volume is already used by pod(s)&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>two pods are using same disk PVC, this issue could happen even using &lt;code>Deployment&lt;/code> with one replica, check detailed explanation and workaround here with above explanation&lt;/p>
&lt;ul>
&lt;li>&lt;code>Multi-Attach error for volume &amp;quot;pvc-0d7740b9-3a43-11e9-93d5-dee1946e6ce9&amp;quot; Volume is already exclusively attached to one node and can't be attached to another&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>This could be a transient error when move volume from one node to another, use following command to find attached node:&lt;/p>
&lt;pre>&lt;code class="language-console" data-lang="console">kubectl get no -o yaml | grep volumesAttached -A 15 | grep pvc-0d7740b9-3a43-11e9-93d5-dee1946e6ce9 -B 10 -A 15
&lt;/code>&lt;/pre>&lt;p>related code: &lt;a href="https://github.com/kubernetes/kubernetes/blob/36e40fb850293076b415ae3d376f5f81dc897105/pkg/controller/volume/attachdetach/reconciler/reconciler.go#L300">reportMultiAttachError&lt;/a>&lt;/p>
&lt;h2 id="26-attached-non-existing-disk-volume-on-agent-node">26. attached non-existing disk volume on agent node&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>There is little possibility that attach/detach disk and disk deletion happened in same time, that would cause race condition. This PR add remediation when attach/detach disk, if returned 404 error, it will filter out all non-existing disks and try attach/detach operation again.&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/88444">fix: add remediation in azure disk attach/detach&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/88620">fix: azure disk remediation issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>1.15.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.18&lt;/td>
&lt;td>1.18.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;p>Detach disk in problem manually&lt;/p>
&lt;h2 id="27-failed-to-get-azure-instance-id-for-node-not-a-vmss-instance">27. failed to get azure instance id for node (not a vmss instance)&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/pull/81266">PR#81266&lt;/a> does not convert the VMSS node name which causes error like this:&lt;/p>
&lt;pre>&lt;code>failed to get azure instance id for node \&amp;quot;k8s-agentpool1-32474172-vmss_1216\&amp;quot; (not a vmss instance)
&lt;/code>&lt;/pre>&lt;p>That will make dangling attach return error, and k8s volume attach/detach controller will getVmssInstance, and since the nodeName is in an incorrect format, it will always clean vmss cache if node not found, thus incur a get vmss API call storm.&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/pull/90749">fix: azure disk dangling attach issue on VMSS which would cause API throttling&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>only hotfixed with image &lt;code>mcr.microsoft.com/oss/kubernetes/hyperkube:v1.14.8-hotfix.20200529.1&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>only hotfixed with image &lt;code>mcr.microsoft.com/oss/kubernetes/hyperkube:v1.15.11-hotfix.20200529.1&lt;/code>, &lt;code>mcr.microsoft.com/oss/kubernetes/hyperkube:v1.15.12-hotfix.20200603&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.10 (also hotfixed with image &lt;code>mcr.microsoft.com/oss/kubernetes/hyperkube:v1.16.9-hotfix.20200529.1&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.18&lt;/td>
&lt;td>1.18.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.19&lt;/td>
&lt;td>1.19.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Work around&lt;/strong>:&lt;/p>
&lt;ol>
&lt;li>Stop kube-controller-manager&lt;/li>
&lt;li>detach disk in problem from that vmss node manually&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-console" data-lang="console">az vmss disk detach -g &amp;lt;RESOURCE_GROUP_NAME&amp;gt; --name &amp;lt;VMSS_NAME&amp;gt; --instance-id &amp;lt;ID(number)&amp;gt; --lun number
&lt;/code>&lt;/pre>&lt;p>e.g. per below logs,&lt;/p>
&lt;pre>&lt;code>E0501 11:15:40.981758 1 attacher.go:277] failed to detach azure disk &amp;quot;/subscriptions/xxx/resourceGroups/rg/providers/Microsoft.Compute/disks/rg-dynamic-pvc-dc282131-b669-47db-8d57-cb3b9789ac3e&amp;quot;, err failed to get azure instance id for node &amp;quot;k8s-agentpool1-32474172-vmss_1216&amp;quot; (not a vmss instance)
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>find lun number of disk &lt;code>rg-dynamic-pvc-dc282131-b669-47db-8d57-cb3b9789ac3e&lt;/code>:&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-console" data-lang="console">az vmss show -g rg --name k8s-agentpool1-32474172-vmss --instance-id 1216
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>detach vmss disk manually:&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-console" data-lang="console">az vmss disk detach -g rg --name k8s-agentpool1-32474172-vmss --instance-id 1216 --lun number
&lt;/code>&lt;/pre>&lt;ol start="3">
&lt;li>Start kube-controller-manager&lt;/li>
&lt;/ol></description></item><item><title>FAQ: AzureFile CSI Driver Known Issues</title><link>https://kubernetes-sigs.github.io/cloud-provider-azure/faq/known-issues/azurefile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://kubernetes-sigs.github.io/cloud-provider-azure/faq/known-issues/azurefile/</guid><description>
&lt;!-- TOC -->
&lt;ul>
&lt;li>&lt;a href="#azure-file-plugin-known-issues">azure file plugin known issues&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#recommended-stable-version-for-azure-file">Recommended stable version for azure file&lt;/a>&lt;/li>
&lt;li>&lt;a href="#1-azure-file-mountoptions-setting">1. azure file mountOptions setting&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#filedir-mode-setting">file/dir mode setting:&lt;/a>&lt;/li>
&lt;li>&lt;a href="#other-useful-mountoptions-setting">other useful &lt;code>mountOptions&lt;/code> setting:&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#2-permission-issue-of-azure-file-dynamic-provision-in-acs-engine">2. permission issue of azure file dynamic provision in acs-engine&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-azure-file-support-on-sovereign-cloud">3. Azure file support on Sovereign Cloud&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-azure-file-dynamic-provision-failed-due-to-cluster-name-length-issue">4. azure file dynamic provision failed due to cluster name length issue&lt;/a>&lt;/li>
&lt;li>&lt;a href="#5-azure-file-dynamic-provision-failed-due-to-no-storage-account-in-current-resource-group">5. azure file dynamic provision failed due to no storage account in current resource group&lt;/a>&lt;/li>
&lt;li>&lt;a href="#6-azure-file-plugin-on-windows-does-not-work-after-node-restart">6. azure file plugin on Windows does not work after node restart&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-file-permission-could-not-be-changed-using-azure-file-eg-postgresql">7. file permission could not be changed using azure file, e.g. postgresql&lt;/a>&lt;/li>
&lt;li>&lt;a href="#8-could-not-delete-pod-with-azurefile-volume-if-storage-account-key-changed">8. Could not delete pod with AzureFile volume if storage account key changed&lt;/a>&lt;/li>
&lt;li>&lt;a href="#9-long-latency-compared-to-disk-when-handling-lots-of-small-files">9. Long latency when handling lots of small files&lt;/a>&lt;/li>
&lt;li>&lt;a href="#10-allow-access-from-selected-network-setting-on-storage-account-will-break-azure-file-dynamic-provisioning">10. &lt;code>allow access from selected network&lt;/code> setting on storage account will break azure file dynamic provisioning&lt;/a>&lt;/li>
&lt;li>&lt;a href="#11-azure-file-remount-on-windows-in-same-node-would-fail">11. azure file remount on Windows in same node would fail&lt;/a>&lt;/li>
&lt;li>&lt;a href="#12-update-azure-file-secret-if-azure-storage-account-key-changed">12. update azure file secret if azure storage account key changed&lt;/a>&lt;/li>
&lt;li>&lt;a href="#13-create-azure-files-pv-authorizationfailure-when-using-advanced-networking">13. Create Azure Files PV AuthorizationFailure when using advanced networking&lt;/a>&lt;/li>
&lt;li>&lt;a href="#14-initial-delay5s-in-mounting-azure-file">14. initial delay(5s) in mounting azure file&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="recommended-stable-version-for-azure-file">Recommended stable version for azure file&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>stable version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.11+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.7+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.2+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.8+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.6+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.4+&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.0+&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="1-azure-file-mountoptions-setting">1. azure file mountOptions setting&lt;/h2>
&lt;h3 id="filedir-mode-setting">file/dir mode setting:&lt;/h3>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>fileMode&lt;/code>, &lt;code>dirMode&lt;/code> value would be different in different versions, in latest master branch, it&amp;rsquo;s &lt;code>0755&lt;/code> by default, to set a different value, follow this &lt;a href="https://github.com/andyzhangx/Demo/blob/master/linux/azurefile/azurefile-mountoptions.md">mount options support of azure file&lt;/a> (available from v1.8.5).&lt;/li>
&lt;li>For version v1.8.0-v1.8.4, since &lt;a href="https://github.com/andyzhangx/Demo/blob/master/linux/azurefile/azurefile-mountoptions.md">mount options support of azure file&lt;/a> is not available, as a workaround, &lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">securityContext&lt;/a> could be specified for the pod, &lt;a href="https://github.com/andyzhangx/Demo/blob/master/linux/azurefile/demo-azurefile-securitycontext.yaml">detailed pod example&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">securityContext&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">runAsUser&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">XXX&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">fsGroup&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">XXX&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>version&lt;/th>
&lt;th>&lt;code>fileMode&lt;/code>, &lt;code>dirMode&lt;/code> value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.6.x, v1.7.x&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8.0 ~ v1.8.5, v1.9.0&lt;/td>
&lt;td>0700&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8.6 or later, v1.9.1 ~ v1.10.9, v1.11.0 ~ v1.11.3, v1.12.0 ~ v.12.1&lt;/td>
&lt;td>0755&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10.10 or later&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11.4 or later&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12.2 or later&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13.x&lt;/td>
&lt;td>0777&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="other-useful-mountoptions-setting">other useful &lt;code>mountOptions&lt;/code> setting:&lt;/h3>
&lt;ul>
&lt;li>&lt;code>mfsymlinks&lt;/code>: make azure file(cifs) mount supports symbolic link&lt;/li>
&lt;li>&lt;code>nobrl&lt;/code>: Do not send byte range lock requests to the server. This is necessary for certain applications that break with cifs style mandatory byte range locks (and most cifs servers do not yet support requesting advisory byte range locks). Error message could be like following:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Error: SQLITE_BUSY: database is locked
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/54610">azureFile volume mode too strict for container with non root user&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/59755">Unable to connect to SQL-lite db mounted on AzureFile/AzureDisks [SQLITE_BUSY: database is locked]&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/61767">Allow nobrl parameter like docker to use sqlite over network drive&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/58308">Error to deploy mongo with azure file storage&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="2-permission-issue-of-azure-file-dynamic-provision-in-acs-engine">2. permission issue of azure file dynamic provision in acs-engine&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>From acs-engine v0.12.0, RBAC is enabled, azure file dynamic provision does not work from this version&lt;/p>
&lt;p>&lt;strong>error logs&lt;/strong>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Warning ProvisioningFailed 8s persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile&amp;#34;&lt;/span>: Couldn&lt;span style="color:#a40000">&amp;#39;&lt;/span>t create secret secrets is forbidden: User &lt;span style="color:#4e9a06">&amp;#34;system:serviceaccount:kube-syste
&lt;/span>&lt;span style="color:#4e9a06">m:persistent-volume-binder&amp;#34;&lt;/span> cannot create secrets in the namespace &lt;span style="color:#4e9a06">&amp;#34;default&amp;#34;&lt;/span>
Warning ProvisioningFailed 8s persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile&amp;#34;&lt;/span>: failed to find a matching storage account
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/59543">azure file PVC need secrets create permission for persistent-volume-binder&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Add a ClusterRole and ClusterRoleBinding for &lt;a href="https://github.com/andyzhangx/Demo/tree/master/linux/azurefile#dynamic-provisioning-for-azure-file-in-linux-support-from-v170">azure file dynamic privision&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">kubectl create -f https://raw.githubusercontent.com/andyzhangx/Demo/master/aks-engine/rbac/azure-cloud-provider-deployment.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>delete the original PVC and recreate PVC&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR in acs-engine: &lt;a href="https://github.com/Azure/acs-engine/pull/2238">fix azure file dynamic provision permission issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="3-azure-file-support-on-sovereign-cloud">3. Azure file support on Sovereign Cloud&lt;/h2>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/pull/48460">Azure file on Sovereign Cloud&lt;/a> is supported from v1.7.11, v1.8.0&lt;/p>
&lt;h2 id="4-azure-file-dynamic-provision-failed-due-to-cluster-name-length-issue">4. azure file dynamic provision failed due to cluster name length issue&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
k8s cluster name length must be less than 16 characters, otherwise following error will be received when creating dynamic privisioning azure file pvc, this bug exists in [v1.7.0, v1.7.10]:&lt;/p>
&lt;blockquote>
&lt;p>Note: check &lt;code>cluster-name&lt;/code> by running &lt;code>grep cluster-name /etc/kubernetes/manifests/kube-controller-manager.yaml&lt;/code> on master node&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">persistentvolume-controller Warning ProvisioningFailed Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile&amp;#34;&lt;/span>: failed to find a matching storage account
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/48326">Fix share name generation in azure file provisioner&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="5-azure-file-dynamic-provision-failed-due-to-no-storage-account-in-current-resource-group">5. azure file dynamic provision failed due to no storage account in current resource group&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When create an azure file PVC, there will be error if there is no storage account in current resource group, error info would be like following:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Warning ProvisioningFailed 10s &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>x5 over 1m&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> persistentvolume-controller Failed to provision volume with StorageClass &lt;span style="color:#4e9a06">&amp;#34;azurefile-premium&amp;#34;&lt;/span>: failed to find a matching storage account
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/56556">failed to create azure file pvc if there is no storage account in current resource group&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:
specify a storage account in azure file dynamic provision, you should make sure the specified storage account is in the same resource group as your k8s cluster. In AKS, the specified storage account should be in &lt;code>shadow resource group&lt;/code>(naming as &lt;code>MC_+{RESOUCE-GROUP-NAME}+{CLUSTER-NAME}+{REGION}&lt;/code>) which contains all resources of your aks cluster.&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/56557">fix the create azure file pvc failure if there is no storage account in current resource group&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>1.7.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="6-azure-file-plugin-on-windows-does-not-work-after-node-restart">6. azure file plugin on Windows does not work after node restart&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
azure file plugin on Windows does not work after node restart, this is due to &lt;code>New-SmbGlobalMapping&lt;/code> cmdlet has lost account name/key after reboot&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/60624">azure file plugin on Windows does not work after node restart&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>delete the original pod with azure file mount&lt;/li>
&lt;li>create the pod again&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/60625">fix azure file plugin failure issue on Windows after node restart&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>not support in upstream&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="7-file-permission-could-not-be-changed-using-azure-file-eg-postgresql">7. file permission could not be changed using azure file, e.g. postgresql&lt;/h2>
&lt;p>&lt;strong>error logs&lt;/strong> when running postgresql on azure file plugin:&lt;/p>
&lt;pre>&lt;code>initdb: could not change permissions of directory &amp;quot;/var/lib/postgresql/data&amp;quot;: Operation not permitted
fixing permissions on existing directory /var/lib/postgresql/data
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Issue details&lt;/strong>:
azure file plugin is using cifs/SMB protocol, file/dir permission could not be changed after mounting&lt;/p>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;p>Use &lt;code>mountOptions&lt;/code> with &lt;code>dir_mode&lt;/code>, &lt;code>file_mode&lt;/code> set as &lt;code>0777&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">kind&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">StorageClass&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">apiVersion&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">storage.k8s.io/v1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">metadata&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">azurefile&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">provisioner&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">kubernetes.io/azure-file&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">mountOptions&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">dir_mode=0777&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#000">file_mode=0777&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>follow detailed config &lt;a href="../linux/azurefile/postgresql">here&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Related issues&lt;/strong>
&lt;a href="https://github.com/Azure/AKS/issues/225">Persistent Volume Claim permissions&lt;/a>&lt;/p>
&lt;h2 id="8-could-not-delete-pod-with-azurefile-volume-if-storage-account-key-changed">8. Could not delete pod with AzureFile volume if storage account key changed&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>kubelet fails to umount azurefile volume when there is azure file connection, below is an easy repro:
&lt;ul>
&lt;li>create a pod with azure file mount&lt;/li>
&lt;li>regenerate the account key of the storage account&lt;/li>
&lt;li>delete the pod, and the pod will never be deleted due to &lt;code>UnmountVolume.TearDown&lt;/code> error&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>error logs&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">nestedpendingoperations.go:263&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Operation &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;\&amp;#34;kubernetes.io/azure-file/cc5c86cd-422a-11e8-91d7-000d3a03ee84-myvolume\&amp;#34; (\&amp;#34;cc5c86cd-422a-11e8-91d7-000d3a03ee84\&amp;#34;)&amp;#34;&lt;/span> failed. No retries permitted &lt;span style="color:#204a87;font-weight:bold">until&lt;/span> 2018-04-17 10:35:40.240272223 +0000 UTC &lt;span style="color:#000">m&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>+1185722.391925424 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>durationBeforeRetry 500ms&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>. Error: &lt;span style="color:#4e9a06">&amp;#34;UnmountVolume.TearDown failed for volume \&amp;#34;myvolume\&amp;#34; (UniqueName: \&amp;#34;kubernetes.io/azure-file/cc5c86cd-422a-11e8-91d7-000d3a03ee84-myvolume\&amp;#34;) pod \&amp;#34;cc5c86cd-422a-11e8-91d7-000d3a03ee84\&amp;#34; (UID: \&amp;#34;cc5c86cd-422a-11e8-91d7-000d3a03ee84\&amp;#34;) : Error checking if path exists: stat /var/lib/kubelet/pods/cc5c86cd-422a-11e8-91d7-000d3a03ee84/volumes/kubernetes.io~azure-file/myvolume: resource temporarily unavailable
&lt;/span>&lt;span style="color:#4e9a06">...
&lt;/span>&lt;span style="color:#4e9a06">kubelet_volumes.go:128] Orphaned pod &amp;#34;&lt;/span>380b02f3-422b-11e8-91d7-000d3a03ee84&lt;span style="color:#4e9a06">&amp;#34; found, but volume paths are still present on disk
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;p>manually umount the azure file mount path on the agent node and then the pod will be deleted right after that&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">sudo umount /var/lib/kubelet/pods/cc5c86cd-422a-11e8-91d7-000d3a03ee84/volumes/kubernetes.io~azure-file/myvolume
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/52324">Fix bug:Kubelet failure to umount mount points&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.7&lt;/td>
&lt;td>no fix(no cherry-pick fix is allowed)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.8&lt;/td>
&lt;td>1.8.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.9&lt;/td>
&lt;td>1.9.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>1.10.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/62824">UnmountVolume.TearDown fails for AzureFile volume, locks up node&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/41141">Kubelet failure to umount glusterfs mount points&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="9-long-latency-compared-to-disk-when-handling-lots-of-small-files">9. Long latency compared to disk when handling lots of small files&lt;/h2>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/223">&lt;code>azurefile&lt;/code> is very slow&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/helm/charts/issues/5751">Can&amp;rsquo;t roll out Wordpress chart with PV on AzureFile&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="10-allow-access-from-selected-network-setting-on-storage-account-will-break-azure-file-dynamic-provisioning">10. &lt;code>allow access from selected network&lt;/code> setting on storage account will break azure file dynamic provisioning&lt;/h2>
&lt;p>When set &lt;code>allow access from selected network&lt;/code> on storage account and will get following error when creating a file share by k8s:&lt;/p>
&lt;pre>&lt;code>persistentvolume-controller (combined from similar events): Failed to provision volume with StorageClass &amp;quot;azurefile&amp;quot;: failed to create share kubernetes-dynamic-pvc-xxx in account xxx: failed to create file share, err: storage: service returned error: StatusCode=403, ErrorCode=AuthorizationFailure, ErrorMessage=This request is not authorized to perform this operation.
&lt;/code>&lt;/pre>&lt;p>That&amp;rsquo;s because k8s &lt;code>persistentvolume-controller&lt;/code> is on master node which is not in the selected network, and that&amp;rsquo;s why it could not create file share on that storage account.&lt;/p>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;p>use azure file static provisioning instead&lt;/p>
&lt;ul>
&lt;li>create azure file share in advance, and then provide storage account and file share name in k8s, here is an &lt;a href="https://docs.microsoft.com/en-us/azure/aks/azure-files-volume">example&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/804">Azure Files PV AuthorizationFailure when using advanced networking &lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="11-azure-file-remount-on-windows-in-same-node-would-fail">11. azure file remount on Windows in same node would fail&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>If user delete a pod with azure file mount in deployment and it would probably schedule a pod on same node, azure file mount will fail since &lt;code>New-SmbGlobalMapping&lt;/code> command would fail if file share is already mounted on the node.&lt;/p>
&lt;p>&lt;strong>error logs&lt;/strong>&lt;/p>
&lt;p>Error logs would be like following:&lt;/p>
&lt;pre>&lt;code>E0118 08:15:52.041014 2112 nestedpendingoperations.go:267] Operation for &amp;quot;\&amp;quot;kubernetes.io/azure-file/42c0ea39-1af9-11e9-8941-000d3af95268-pvc-d7e1b5f9-1af3-11e9-8941-000d3af95268\&amp;quot; (\&amp;quot;42c0ea39-1af9-11e9-8941-000d3af95268\&amp;quot;)&amp;quot; failed. No retries permitted until 2019-01-18 08:15:53.0410149 +0000 GMT m=+732.446642701 (durationBeforeRetry 1s). Error: &amp;quot;MountVolume.SetUp failed for volume \&amp;quot;pvc-d7e1b5f9-1af3-11e9-8941-000d3af95268\&amp;quot; (UniqueName: \&amp;quot;kubernetes.io/azure-file/42c0ea39-1af9-11e9-8941-000d3af95268-pvc-d7e1b5f9-1af3-11e9-8941-000d3af95268\&amp;quot;) pod \&amp;quot;deployment-azurefile-697f98d559-6zrlf\&amp;quot; (UID: \&amp;quot;42c0ea39-1af9-11e9-8941-000d3af95268\&amp;quot;) : azureMount: SmbGlobalMapping failed: exit status 1, only SMB mount is supported now, output: \&amp;quot;New-SmbGlobalMapping : Generic failure \\r\\nAt line:1 char:190\\r\\n+ ... ser, $PWord;New-SmbGlobalMapping -RemotePath $Env:smbremotepath -Cred ...\\r\\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\r\\n + CategoryInfo : NotSpecified: (MSFT_SmbGlobalMapping:ROOT/Microsoft/...mbGlobalMapping) [New-SmbGlobalMa \\r\\n pping], CimException\\r\\n + FullyQualifiedErrorId : HRESULT 0x80041001,New-SmbGlobalMapping\\r\\n \\r\\n\&amp;quot;&amp;quot;
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/73661">fix smb remount issue on Windows&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.10&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.11&lt;/td>
&lt;td>1.11.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.12&lt;/td>
&lt;td>1.12.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.13&lt;/td>
&lt;td>1.13.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.14&lt;/td>
&lt;td>1.14.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/73087">azure file remount on Windows in same node would fail&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Azure/aks-engine/issues/327">Mounting volume to pods fails randomly&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="12-update-azure-file-secret-if-azure-storage-account-key-changed">12. update azure file secret if azure storage account key changed&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:
There would be azure file mount failure if azure storage account key changed&lt;/p>
&lt;p>&lt;strong>Workaround&lt;/strong>:
User needs to update &lt;code>azurestorageaccountkey&lt;/code> field manually in azure file secret(secret name format: &lt;code>azure-storage-account-{storage-account-name}-secret&lt;/code> in &lt;code>default&lt;/code> namespace):&lt;/p>
&lt;pre>&lt;code>kubectl delete secret azure-storage-account-{storage-account-name}-secret
kubectl create secret generic azure-storage-account-{storage-account-name}-secret --from-literal azurestorageaccountname=... --from-literal azurestorageaccountkey=&amp;quot;...&amp;quot; --type=Opaque
&lt;/code>&lt;/pre>&lt;blockquote>
&lt;p>make sure there is no &lt;code>\r&lt;/code> in the account name and key, here is a &lt;a href="https://github.com/MicrosoftDocs/azure-docs/issues/61650#issuecomment-683274588">failed case&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>delete original pod(may use &lt;code>--force --grace-period=0&lt;/code>) and wait a few minutes for new pod retry azure file mount&lt;/li>
&lt;/ul>
&lt;h2 id="13-create-azure-files-pv-authorizationfailure-when-using-advanced-networking">13. Create Azure Files PV AuthorizationFailure when using advanced networking&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When create an azure file PV using advanced networking, user may hit following error:&lt;/p>
&lt;pre>&lt;code>err: storage: service returned error: StatusCode=403, ErrorCode=AuthorizationFailure, ErrorMessage=This request is not authorized to perform this operation
&lt;/code>&lt;/pre>&lt;p>Before api-version &lt;code>2019-06-01&lt;/code>, create file share action is considered as data-path operation, since &lt;code>2019-06-01&lt;/code>, it would be considered as control-path operation, not blocked by advanced networking any more.&lt;/p>
&lt;p>&lt;strong>Related issues&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Azure/AKS/issues/804">Azure Files PV AuthorizationFailure when using advanced networking&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/85354">Azure Files PV AuthorizationFailure when using advanced networking&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/90350">Switch to use AzureFile management SDK&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.18&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.19&lt;/td>
&lt;td>1.19.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Workaround&lt;/strong>:&lt;/p>
&lt;p>Shut down the advanced networking when create azure file PV.&lt;/p>
&lt;h2 id="14-initial-delay5s-in-mounting-azure-file">14. initial delay(5s) in mounting azure file&lt;/h2>
&lt;p>&lt;strong>Issue details&lt;/strong>:&lt;/p>
&lt;p>When starting pods with AFS volumes, there is an initial delay of five seconds until the pod is transitioning from the &amp;ldquo;Scheduled&amp;rdquo; state. The reason for this is that currently the volume mounting happens inside a wait.Poll which will initially wait a specified interval(currently 5 seconds) before execution. This issue is introduced by PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/88610">fix: azure file mount timeout issue&lt;/a> with v1.15.11+, v1.16.8+, v1.17.4+, v1.18.0+&lt;/p>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/issues/93025">initial delay(5s) when starting Pods with Azure File volumes&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Fix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>PR &lt;a href="https://github.com/kubernetes/kubernetes/pull/93052">fix: initial delay in mounting azure disk &amp;amp; file&lt;/a>&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>k8s version&lt;/th>
&lt;th>fixed version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>v1.15&lt;/td>
&lt;td>no fix&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.16&lt;/td>
&lt;td>1.16.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.17&lt;/td>
&lt;td>1.17.10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.18&lt;/td>
&lt;td>1.18.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>v1.19&lt;/td>
&lt;td>1.19.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item></channel></rss>